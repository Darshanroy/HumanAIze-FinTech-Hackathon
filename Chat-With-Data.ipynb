{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking multiple FAQ questions and Building a chatbot for that with multiple data sources inclduing the homepage also\n",
    "## Takinng out the questions and making it into the CSV formate for laoding\n",
    "## Creating  a well documented files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import RecursiveUrlLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.chains import HypotheticalDocumentEmbedder\n",
    "from langchain_chroma import Chroma\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']= \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\91845\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "hf_embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model= \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    task=\"feature-extraction\",\n",
    "    huggingfacehub_api_token=\"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\",\n",
    ")\n",
    "\n",
    "Llama3LLM = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=10000,\n",
    "    do_sample=False,\n",
    ")\n",
    "Llama3LLMHydeEmbeddings = HypotheticalDocumentEmbedder.from_llm(Llama3LLM,\n",
    "                                                  hf_embeddings,\n",
    "                                                  prompt_key = \"web_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "just give main Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets and their corresponding directory paths\n",
    "datasets = {\n",
    "    \"corruption\": r\"CRIME-DATASETS\\corruption\",\n",
    "    \"divorce\": r\"CRIME-DATASETS\\divorce\",\n",
    "    \"property\": r\"CRIME-DATASETS\\property\",\n",
    "    \"rape\": r\"CRIME-DATASETS\\rape\",\n",
    "    \"robbery\": r\"CRIME-DATASETS\\Robbery\",\n",
    "    \"sexual_assault\": r\"CRIME-DATASETS\\sexual assault\"\n",
    "}\n",
    "\n",
    "# Dictionary to store the documents for each dataset\n",
    "documents = {}\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)\n",
    "\n",
    "# Loop through each dataset, load and split the documents\n",
    "for key, path in datasets.items():\n",
    "    loader = PyPDFDirectoryLoader(path)\n",
    "    docs = loader.load()\n",
    "    documents[key] = text_splitter.split_documents(docs)\n",
    "\n",
    "# Now documents['corruption'], documents['divorce'], etc. contain the split documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the retrievers for each document type\n",
    "retrievers = {}\n",
    "\n",
    "# Loop through each document type and create the Chroma DB and retriever\n",
    "for doc_type in documents.keys():\n",
    "    docs = f\"documents_{doc_type}\"\n",
    "    docs = documents[doc_type]  # Get the documents by name\n",
    "    persist_directory = f\"./chroma_{doc_type}\"\n",
    "    Llama3LLMDB = Chroma.from_documents(docs, Llama3LLMHydeEmbeddings, persist_directory=persist_directory)\n",
    "    retriever = Llama3LLMDB.as_retriever(type=\"similarity\")\n",
    "    retrievers[doc_type] = retriever\n",
    "\n",
    "# Example of accessing a retriever\n",
    "DocumentChainMistralLLM = create_stuff_documents_chain(Llama3LLM,prompt)\n",
    "RetrievalChainMistralLLM = create_retrieval_chain(retrievers['rape'],DocumentChainMistralLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocumentChainMistralLLM = create_stuff_documents_chain(Llama3LLM,prompt)\n",
    "RetrievalChainMistralLLM = create_retrieval_chain(retrievers['rape'],DocumentChainMistralLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    MistralOutput = RetrievalChainMistralLLM.invoke({\"input\":\"Code of Criminal Procedure, 1973; Penal Code, 1860?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is the provision related to the suspension of the execution of a sentence pending an appeal?\n",
      "\n",
      "Answer: The provision related to the suspension of the execution of a sentence pending an appeal in the Code of Criminal Procedure, 1973 (Cr.PC) can be found in Section 389 of the code. This section deals with the power of the High Court to suspend the execution of a sentence pending an appeal. However, the Penal Code, 1860 (IPC) does not contain provisions related to the suspension of execution of a sentence.\n"
     ]
    }
   ],
   "source": [
    "print(MistralOutput['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
